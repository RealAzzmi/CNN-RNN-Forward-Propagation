Experiment: lstm_units_64
==================================================

Configuration:
  vocab_size: 2743
  embedding_dim: 128
  lstm_units: 64
  num_lstm_layers: 1
  bidirectional: False
  dropout_rate: 0.3
  dense_units: 32
  num_classes: 3
  max_sequence_length: 128

Validation Results:
  Macro F1: 0.6882
  Accuracy: 0.6900

Test Results:
  Macro F1: 0.7608
  Accuracy: 0.7650

Classification Report:
{'negative': {'precision': 0.7300613496932515, 'recall': 0.7777777777777778, 'f1-score': 0.7531645569620253, 'support': 153.0}, 'neutral': {'precision': 0.6857142857142857, 'recall': 0.75, 'f1-score': 0.7164179104477612, 'support': 96.0}, 'positive': {'precision': 0.8712121212121212, 'recall': 0.7615894039735099, 'f1-score': 0.8127208480565371, 'support': 151.0}, 'accuracy': 0.765, 'macro avg': {'precision': 0.7623292522065528, 'recall': 0.7631223939170959, 'f1-score': 0.7607677718221079, 'support': 400.0}, 'weighted avg': {'precision': 0.7727024705866731, 'recall': 0.765, 'f1-score': 0.7668278616867801, 'support': 400.0}}