Experiment: lstm_units_64
==================================================

Configuration:
  vocab_size: 2743
  embedding_dim: 128
  lstm_units: 64
  num_lstm_layers: 1
  bidirectional: False
  dropout_rate: 0.3
  dense_units: 32
  num_classes: 3
  max_sequence_length: 128

Validation Results:
  Macro F1: 0.7566
  Accuracy: 0.7700

Test Results:
  Macro F1: 0.7169
  Accuracy: 0.7400

Classification Report:
{'negative': {'precision': 0.6565656565656566, 'recall': 0.8496732026143791, 'f1-score': 0.7407407407407407, 'support': 153.0}, 'neutral': {'precision': 0.7796610169491526, 'recall': 0.4791666666666667, 'f1-score': 0.5935483870967742, 'support': 96.0}, 'positive': {'precision': 0.8391608391608392, 'recall': 0.7947019867549668, 'f1-score': 0.8163265306122449, 'support': 151.0}, 'accuracy': 0.74, 'macro avg': {'precision': 0.7584625042252161, 'recall': 0.7078472853453376, 'f1-score': 0.7168718861499199, 'support': 400.0}, 'weighted avg': {'precision': 0.7550382244873771, 'recall': 0.74, 'f1-score': 0.7339482115426815, 'support': 400.0}}